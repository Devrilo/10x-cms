# ğŸ§ª Playwright Context Experiment Guide

## ğŸ¯ Cel eksperymentu

Sprawdzenie, ktÃ³ra metoda dostarczania kontekstu jest najefektywniejsza przy pracy z najnowszymi features Playwright 1.56.1.

## ğŸ“ Zadanie programistyczne

**Cel:** StwÃ³rz test suite dla DDD API (v2) uÅ¼ywajÄ…c Playwright Test z nastÄ™pujÄ…cymi wymaganiami:

### Wymagania techniczne:
1. âœ… **Test Fixtures** - wÅ‚asny fixture `authenticatedAPI` z dependency injection
2. âœ… **API Request Context** - wykorzystanie Playwright API dla testÃ³w REST
3. âœ… **Soft Assertions** - uÅ¼ycie `expect.soft()` do walidacji wielu pÃ³l
4. âœ… **Custom Matcher** - wÅ‚asny matcher `toHaveDDDEventStructure()` sprawdzajÄ…cy strukturÄ™ domain events
5. âœ… **Storage State** - wspÃ³Å‚dzielony stan autentykacji miÄ™dzy testami
6. âœ… **Parallel Execution** - testy uruchamiane rÃ³wnolegle

### FunkcjonalnoÅ›Ä‡ do przetestowania:
- Endpoint: `POST /api/v2/content-types` - utworzenie ContentType
- Endpoint: `POST /api/v2/content` - utworzenie content
- Endpoint: `POST /api/v2/content/:id/publish` - publikacja content
- Endpoint: `GET /api/v2/events/:aggregateId` - pobranie event history

### Struktura DDD Event (dla custom matcher):
```typescript
{
  id: string,
  aggregateId: string,
  aggregateType: string,
  eventType: string,
  eventData: object,
  occurredAt: string (ISO date),
  version: number
}
```

## ğŸ”„ Workflow eksperymentu

### Przygotowanie (TEN CHAT)
1. Przeczytaj caÅ‚Ä… instrukcjÄ™
2. Zapoznaj siÄ™ z promptami dla kaÅ¼dej metody
3. Zrozum kryteria weryfikacji

### Wykonanie (NOWY CHAT z Claude Sonnet 3.5)

Dla kaÅ¼dej metody (1-4):

#### Krok 1: OtwÃ³rz nowy chat
- UÅ¼yj **Claude Sonnet 3.5**
- KaÅ¼da metoda = OSOBNA rozmowa (fresh context)

#### Krok 2: Skopiuj odpowiedni prompt
- PrzejdÅº do sekcji "Prompty do uÅ¼ycia" poniÅ¼ej
- Skopiuj prompt dla danej metody (1-4)
- Dla metody 2: doÅ‚Ä…cz fragmenty dokumentacji
- Dla metody 4: doÅ‚Ä…cz plik llms.txt

#### Krok 3: Uruchom eksperyment
- Wklej prompt do Claude Sonnet 3.5
- **ZACZNIJ MIERZYÄ† CZAS** â±ï¸
- PozwÃ³l Claude wygenerowaÄ‡ rozwiÄ…zanie
- Zapisz wygenerowany kod w odpowiednim folderze

#### Krok 4: Iteracje
- JeÅ›li kod nie dziaÅ‚a, kontynuuj konwersacjÄ™
- Polecenie: "Ten kod ma bÅ‚Ä™dy: [wklej bÅ‚Ä™dy]. Popraw."
- Licznik iteracji: ile razy trzeba byÅ‚o poprawiÄ‡?

#### Krok 5: Weryfikacja (POWRÃ“T DO TEGO CHATU)
- WrÃ³Ä‡ tutaj z wygenerowanym kodem
- Powiedz mi: "SprawdÅº metodÄ™ X, oto wygenerowany kod"
- PrzeprowadzÄ™ weryfikacjÄ™ wedÅ‚ug checklist

#### Krok 6: Dokumentacja wynikÃ³w
- UzupeÅ‚nij plik `RESULTS.md` w folderze metody
- Zapisz metryki (czas, iteracje, tokeny)

### Analiza (TEN CHAT)
- Po zakoÅ„czeniu wszystkich 4 metod
- PorÃ³wnamy wyniki i wyciÄ…gniemy wnioski

## ğŸ“Š Metryki do zmierzenia

Dla kaÅ¼dej metody zapisz:

### 1. PoprawnoÅ›Ä‡ kodu (0-100%)
- [ ] Kod siÄ™ kompiluje (TypeScript)
- [ ] Testy przechodzÄ…
- [ ] Fixtures dziaÅ‚ajÄ… poprawnie
- [ ] API calls sÄ… prawidÅ‚owe
- [ ] Custom matcher dziaÅ‚a
- [ ] Soft assertions uÅ¼yte prawidÅ‚owo

### 2. Halucynacje
- Liczba nieistniejÄ…cych API/metod
- Liczba bÅ‚Ä™dnych skÅ‚adni
- Liczba niepoprawnych zaÅ‚oÅ¼eÅ„

### 3. Czas i iteracje
- Czas caÅ‚kowity (minuty)
- Liczba iteracji do dziaÅ‚ajÄ…cego kodu
- Liczba bÅ‚Ä™dÃ³w kompilacji
- Liczba bÅ‚Ä™dÃ³w runtime

### 4. Kontekst
- Liczba tokenÃ³w w prompcie
- Czy kontekst byÅ‚ wystarczajÄ…cy?
- Czy byÅ‚y nadmiarowe informacje?

## âš ï¸ WaÅ¼ne zasady

1. **Jedna metoda = jeden chat** - nie mieszaj kontekstÃ³w
2. **DokÅ‚adnie kopiuj prompty** - Å¼adnych modyfikacji
3. **Mierz czas od pierwszego promptu** do dziaÅ‚ajÄ…cego kodu
4. **Zapisuj wszystko** - kaÅ¼dy bÅ‚Ä…d, kaÅ¼dÄ… iteracjÄ™
5. **BÄ…dÅº obiektywny** - nie pomagaj Claude, niech radzi sobie sam
6. **Wracaj tutaj po weryfikacjÄ™** - ja sprawdzÄ™ poprawnoÅ›Ä‡

## ğŸ“ Struktura folderÃ³w

```
e2e/experiment/
â”œâ”€â”€ EXPERIMENT_GUIDE.md          # Ten plik - instrukcja
â”œâ”€â”€ PROMPTS.md                   # Prompty dla kaÅ¼dej metody
â”œâ”€â”€ VERIFICATION_CHECKLIST.md   # Kryteria oceny
â”œâ”€â”€ RESULTS_TEMPLATE.md         # Template wynikÃ³w
â”œâ”€â”€ PLAYWRIGHT_DOCS.md          # Fragmenty dokumentacji (metoda 2)
â”œâ”€â”€ playwright-llms.txt         # PeÅ‚ny llms.txt (metoda 4)
â”œâ”€â”€ gold-standard/
â”‚   â””â”€â”€ api-ddd.spec.ts         # Wzorcowy test (referencja)
â”œâ”€â”€ method-1-baseline/
â”‚   â”œâ”€â”€ api-ddd.spec.ts         # Wygenerowany kod
â”‚   â””â”€â”€ RESULTS.md              # Wyniki metody 1
â”œâ”€â”€ method-2-manual-docs/
â”‚   â”œâ”€â”€ api-ddd.spec.ts
â”‚   â””â”€â”€ RESULTS.md
â”œâ”€â”€ method-3-context7/
â”‚   â”œâ”€â”€ api-ddd.spec.ts
â”‚   â””â”€â”€ RESULTS.md
â””â”€â”€ method-4-llms-txt/
    â”œâ”€â”€ api-ddd.spec.ts
    â””â”€â”€ RESULTS.md
```

## ğŸš€ Gotowy do startu?

1. âœ… Przeczytaj `PROMPTS.md` - poznaj wszystkie 4 prompty
2. âœ… Przejrzyj `VERIFICATION_CHECKLIST.md` - wiedz, co bÄ™dzie sprawdzane
3. âœ… Zobacz `gold-standard/api-ddd.spec.ts` - poznaj wzorcowe rozwiÄ…zanie
4. âœ… OtwÃ³rz nowy chat z Claude Sonnet 3.5
5. âœ… Zacznij od **Metody 1: Baseline**

---

## ğŸ“ Kontakt z gÅ‚Ã³wnym chatem

Gdy bÄ™dziesz gotowy do weryfikacji, wrÃ³Ä‡ tutaj i napisz:

```
SprawdÅº metodÄ™ [1/2/3/4], oto kod:
[wklej wygenerowany kod]

Metryki:
- Czas: X minut
- Iteracje: Y
- BÅ‚Ä™dy: Z
```

Powodzenia! ğŸ¯
